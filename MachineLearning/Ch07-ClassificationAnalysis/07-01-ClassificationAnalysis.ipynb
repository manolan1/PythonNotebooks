{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PCx-mtOzlhNP"
   },
   "source": [
    "# Classification Analysis\n",
    "\n",
    "### Read in a set of data and examine it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JYKsqCNglhNR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('CreditCardFraud.csv')\n",
    "\n",
    "print (df.shape, df.columns)\n",
    "train_size = .3\n",
    "test_size = .1\n",
    "\n",
    "print (df.head())\n",
    "print (df.isFraud.value_counts())\n",
    "print (df.type.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mn1AZlPlhNW"
   },
   "source": [
    "### Keep the columns we want and change the type to code numbers instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lz3S1g6elhNX"
   },
   "outputs": [],
   "source": [
    "columns = ['type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud', 'isFraud']\n",
    "df = df[columns]\n",
    "df.type = pd.Categorical(df.type).codes\n",
    "print (df.shape, df.columns)\n",
    "print (df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKQQPPfflhNb"
   },
   "source": [
    "### Prepare train & test sets with desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oF8rjfsJlhNd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pp\n",
    "dfNB = df\n",
    "trainNB_X, testNB_X, trainNB_Y, testNB_Y = train_test_split(dfNB[dfNB.columns[:-1]], dfNB.isFraud, train_size = train_size, test_size = test_size)\n",
    "print(testNB_Y.value_counts())\n",
    "print(trainNB_Y.value_counts() / trainNB_Y.count())\n",
    "print(testNB_Y.value_counts() / testNB_Y.count())\n",
    "print(trainNB_X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kusVp-VnlhNg"
   },
   "source": [
    "## Create a Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iOMjiVP9lhNh"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "modelNB = GaussianNB()\n",
    "modelNB.fit(trainNB_X, trainNB_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIHKzxzrlhNm"
   },
   "source": [
    "### Examine the results of Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gu9BVBrrlhNo"
   },
   "outputs": [],
   "source": [
    "predNB_Y = modelNB.predict(testNB_X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testNB_Y, predNB_Y)\n",
    "print (cm)\n",
    "\n",
    "# helper function to print confusion matrix as percentages\n",
    "def cm_percent(cm, length, legend = True):\n",
    "    import numpy as np\n",
    "    if legend:\n",
    "       print (' PC', 'FP\\n', 'FN', 'PW')\n",
    "    return np.ndarray(shape = (2,2), buffer = np.array([100 *(cm[0][0] + cm[1][1])/length,\n",
    "       100 * cm[0][1]/length, 100 * cm[1][0]/length, 100 * (cm[1][0] + cm[0][1])/length]))\n",
    "\n",
    "cmp = cm_percent(cm, len(testNB_Y))\n",
    "print (cmp)\n",
    "print (testNB_Y.value_counts())\n",
    "print (len(testNB_Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9_n3marlhNs"
   },
   "source": [
    "## Save a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M7Zr_8WklhNt"
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(modelNB, 'modelNB.joblib') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJWFouMwlhNw"
   },
   "source": [
    "## Load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OMBMLAFOlhNy"
   },
   "outputs": [],
   "source": [
    "modelNB2 = load('modelNB.joblib')\n",
    "predNB_Y = modelNB2.predict(testNB_X)\n",
    "cm = confusion_matrix(testNB_Y, predNB_Y)\n",
    "print (cm)\n",
    "cmp = cm_percent(cm, len(testNB_Y))\n",
    "print (cmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vnIYVeFzlhN3"
   },
   "source": [
    "## Train the Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIMBWf5zlhN5"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dfDT = df\n",
    "trainDT_X, testDT_X, trainDT_Y, testDT_Y = train_test_split(dfDT[dfDT.columns[:-1]], dfDT.isFraud, train_size = train_size, test_size = test_size)\n",
    "\n",
    "modelDT = DecisionTreeClassifier()\n",
    "modelDT.fit(trainDT_X, trainDT_Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l6EblXsClhN8"
   },
   "source": [
    "## Examine the results of the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XB47qZLplhN-"
   },
   "outputs": [],
   "source": [
    "def important_features(model, columns):\n",
    "    return pd.DataFrame(model.feature_importances_, columns = ['Importance'], index = columns).sort_values(['Importance'], ascending = False)\n",
    " \n",
    "predDT_Y = modelDT.predict(testDT_X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testDT_Y, predDT_Y)\n",
    "print (cm)\n",
    "print (cm_percent(cm, len(testDT_Y)))\n",
    "print (testDT_Y.value_counts(), len(testDT_Y))\n",
    "print (important_features(modelDT, trainDT_X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFqHSW1nlhOd"
   },
   "source": [
    "## Prepare the data\n",
    "### Logistic Regression requires categorical data be dummy encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRaTpXWMlhOe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pp\n",
    "def dummy_code(data, columns, drop_first = True):\n",
    "    for c in columns:\n",
    "        dummies = pd.get_dummies(data[c], prefix = c, drop_first = drop_first)\n",
    "        i = list(data.columns).index(c)\n",
    "        data = pd.concat([data.iloc[:,:i], dummies, data.iloc[:,i+1:]], axis = 1)\n",
    "    return data\n",
    "\n",
    "dfLR = dummy_code(df, ['type'], drop_first = True)\n",
    "trainLR_X, testLR_X, trainLR_Y, testLR_Y = train_test_split(dfLR.iloc[:,dfLR.columns != 'isFraud'], dfLR.isFraud, train_size = train_size, test_size = test_size)\n",
    "\n",
    "print (testLR_X.columns)\n",
    "print (testLR_X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_jje5i7zlhOn"
   },
   "source": [
    "## Create a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4hcmFoNIlhOq"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "modelLR = LogisticRegression(multi_class = 'auto', solver = 'lbfgs')\n",
    "modelLR.fit(trainLR_X, trainLR_Y)\n",
    "print(modelLR.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eQBvfbCilhOt"
   },
   "source": [
    "## Examine the results of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O7gJdlFelhOu"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "predLR_Y = modelLR.predict(testLR_X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "score = modelLR.score(testLR_X, testLR_Y)\n",
    "mse = np.mean((predLR_Y - testLR_Y)**2)\n",
    "print (score, mse)\n",
    "\n",
    "cm = confusion_matrix(testLR_Y, predLR_Y)\n",
    "print (cm)\n",
    "cmp = cm_percent(cm, len(testLR_Y))\n",
    "print (cmp)\n",
    "\n",
    "predLR_Y1 = modelLR.predict_proba(testLR_X)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "roc = roc_auc_score(testLR_Y, predLR_Y)\n",
    "fpr, tpr, x = roc_curve(testLR_Y, predLR_Y1[:,1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr, label = 'AUC = ' + str(roc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "#import scikitplot.metrics as skplt\n",
    "#import matplotlib.pyplot as plt\n",
    "#skplt.plot_roc(testY, predY1)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTgCGR1XlhOy"
   },
   "source": [
    "## Try Logistic Regression with different probability thresholds to change ratio of false negatives and positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5CcSOW6YlhOz"
   },
   "outputs": [],
   "source": [
    "predLR_Y = modelLR.predict_proba(testLR_X)\n",
    "print (predLR_Y[:10])\n",
    "print ('Score', modelLR.score(testLR_X, testLR_Y))\n",
    "\n",
    "for threshold in range(30, 91, 10):\n",
    "    predLR_Y1 = np.where(predLR_Y[:,0] >= threshold/100, 0, 1)\n",
    "    mse = np.mean((predLR_Y1 - testLR_Y)**2)\n",
    "    cm = confusion_matrix(testLR_Y, predLR_Y1)\n",
    "    print ('\\nTHRESHOLD', threshold, 'MSE', mse)\n",
    "    print (cm)\n",
    "    print (cm_percent(cm, len(testLR_Y), legend = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t2zNQoQblhO6"
   },
   "source": [
    "## Prepare the data for a Neural Network\n",
    "### This time you should not drop the first column when dummy encoding. Additionally, data works better if it is rescaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W28T7EjClhO7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pp\n",
    "# rescale the data\n",
    "dfNN = dummy_code(df, ['type'], drop_first = False)\n",
    "print (dfNN.columns)\n",
    "dfNN[['amount',  'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']] /= dfNN[['amount',  'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']].max()\n",
    "trainNN_X, testNN_X, trainNN_Y, testNN_Y = train_test_split(dfNN.iloc[:,dfNN.columns != 'isFraud'], dfNN.isFraud, train_size = train_size, test_size = test_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tcfBRlA8lhPC"
   },
   "source": [
    "## Create a Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HnUlj-TlhPD"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "modelNN = MLPClassifier(hidden_layer_sizes = (5, 3, 2), activation = 'logistic')\n",
    "modelNN.fit(trainNN_X, trainNN_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eyo1DTHYlhPJ"
   },
   "source": [
    "## Examine the results of Neural Network predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WD0s5Z0lhPL"
   },
   "outputs": [],
   "source": [
    "predNN_Y = modelNN.predict(testNN_X)\n",
    "cm = confusion_matrix(testNN_Y, predNN_Y)\n",
    "print (cm)\n",
    "cmp = cm_percent(cm, len(testNN_Y))\n",
    "print (cmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_SWOc1o2lhPO"
   },
   "source": [
    "## Create a SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNuyggKylhPQ"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "train_size = .03\n",
    "test_size = .01\n",
    "dfSVM = dfNN\n",
    "trainSVM_X, testSVM_X, trainSVM_Y, testSVM_Y = train_test_split(dfSVM.iloc[:,dfSVM.columns != 'isFraud'], dfSVM.isFraud, train_size = train_size, test_size = test_size)\n",
    "\n",
    "def do_SVM(kernel, gamma):\n",
    "    print ('\\nKernel:', kernel, 'Gamma:', gamma)\n",
    "    modelSVM = svm.SVC(gamma = gamma,  kernel = kernel)\n",
    "    modelSVM.fit(trainSVM_X, trainSVM_Y)\n",
    "    print (modelSVM.score(testSVM_X, testSVM_Y))\n",
    "\n",
    "    predSVM_Y = modelSVM.predict(testSVM_X)\n",
    "    cm = confusion_matrix(testSVM_Y, predSVM_Y)\n",
    "    print (cm)\n",
    "\n",
    "do_SVM('linear', gamma='auto')\n",
    "\n",
    "for kernel in ['rbf', 'poly', 'sigmoid']:\n",
    "    for gamma in ['auto', 10, 100]:\n",
    "        if not (kernel == 'poly' and gamma == 100):\n",
    "           do_SVM(kernel, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7TSdxMAlhPb"
   },
   "outputs": [],
   "source": [
    "modelSVM = svm.SVC(gamma = 100)\n",
    "modelSVM.fit(trainSVM_X, trainSVM_Y)\n",
    "print(modelSVM.score(testSVM_X, testSVM_Y))\n",
    "predSVM_Y = modelSVM.predict(testSVM_X)\n",
    "print(confusion_matrix(testSVM_Y, predSVM_Y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZEVweEHXlhOB"
   },
   "source": [
    "## Create and train a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "To_f6JTWlhOC"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF = RandomForestClassifier(n_estimators=10)\n",
    "trainRF_X, trainRF_Y, testRF_X, testRF_Y = trainDT_X, trainDT_Y, testDT_X, testDT_Y\n",
    "modelRF.fit(trainRF_X, trainRF_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lycJ3JJZlhOI"
   },
   "source": [
    "## Test the accuracy of the predictions and examine important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-4yKn4pklhOJ"
   },
   "outputs": [],
   "source": [
    "predRF_Y = modelRF.predict(testRF_X)\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy:\",metrics.accuracy_score(testRF_Y, predRF_Y))\n",
    "cm = confusion_matrix(testRF_Y, predRF_Y)\n",
    "print (cm)\n",
    "\n",
    "import pandas as pd\n",
    "feature_imp = pd.Series(modelRF.feature_importances_,index=trainRF_X.columns).sort_values(ascending=False)\n",
    "print (feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Iqv4i89lhOM"
   },
   "source": [
    "## Visualize important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLly66iulhON"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-bGX1pYklhOR"
   },
   "source": [
    "## Try removing less important features and retrain it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtPKVlDKlhOS"
   },
   "outputs": [],
   "source": [
    "newTrainRF_X = trainRF_X[['newbalanceDest', 'oldbalanceOrg', 'amount', 'oldbalanceDest']]\n",
    "newTestRF_X = testRF_X[['newbalanceDest', 'oldbalanceOrg', 'amount', 'oldbalanceDest']]\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF = RandomForestClassifier(n_estimators=10)\n",
    "modelRF.fit(newTrainRF_X, trainRF_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BhtCXClKlhOY"
   },
   "source": [
    "### In this case the accuracy did not go up, but in many cases it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhFbYZ2slhOa"
   },
   "outputs": [],
   "source": [
    "newpredRF_Y = modelRF.predict(newTestRF_X)\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy:\",metrics.accuracy_score(testRF_Y, newpredRF_Y))\n",
    "cm = confusion_matrix(testRF_Y, newpredRF_Y)\n",
    "print (cm)\n",
    "\n",
    "import pandas as pd\n",
    "feature_imp = pd.Series(modelRF.feature_importances_,index=newTrainRF_X.columns).sort_values(ascending=False)\n",
    "print (feature_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lh0Dviv-lhPg"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "modelVC = VotingClassifier(estimators=[('dt', modelDT), ('nb', modelNB)], voting='hard')\n",
    "modelVC.fit(trainDT_X, trainDT_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modelVC.score(testDT_X,testDT_Y))\n",
    "\n",
    "predVC_Y = modelVC.predict(testDT_X)\n",
    "cm = confusion_matrix(testDT_Y, predVC_Y)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "modelNN = MLPClassifier(hidden_layer_sizes = (5, 3, 2), activation = 'logistic')\n",
    "modelNN.fit(trainLR_X, trainLR_Y)\n",
    "\n",
    "predLR = (modelLR.predict_proba(testLR_X))[:,0]\n",
    "predNN = (modelNN.predict_proba(testLR_X))[:,0]\n",
    "\n",
    "predAvg = (predLR + predNN) / 2\n",
    "predAvg1 = np.where(predAvg >= .7, 0, 1)\n",
    "\n",
    "print (confusion_matrix(testLR_Y, predAvg1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Notebook"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "07-01-ClassificationAnalysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
